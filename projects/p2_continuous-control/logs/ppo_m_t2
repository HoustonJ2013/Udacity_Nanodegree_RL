Namespace(actor_fc_units=16, batch_size=128, buffer_size=10000, critic_fc_units1=4, critic_fc_units2=10, critic_fc_units3=10, device='cpu', env='MountainCarContinuous-v0', evaluate_n_iter=50, gamma=0.99, loss='mse', lr=0.0005, lr_actor=0.001, lr_critic=0.005, max_t=2000, n_iterations=200, per=False, save_replay=False, score_threshold=200, score_window_size=100, std_decay=0.99, std_end=0.05, std_start=1.0, tau=0.001, testname='ppo_mountain_t1', update_every=1, weight_decay=0, workers=8)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
Current environment is  MountainCarContinuous-v0
State size is 2
action size is 1
A typical state looks like [[0.43396479 0.5       ]]
Test parameters Namespace(actor_fc_units=16, batch_size=128, buffer_size=10000, critic_fc_units1=4, critic_fc_units2=10, critic_fc_units3=10, device='cpu', env='MountainCarContinuous-v0', evaluate_n_iter=50, gamma=0.99, loss='mse', lr=0.0005, lr_actor=0.001, lr_critic=0.005, max_t=2000, n_iterations=200, per=False, save_replay=False, score_threshold=200, score_window_size=100, std_decay=0.99, std_end=0.05, std_start=1.0, tau=0.001, testname='ppo_mountain_t1', update_every=1, weight_decay=0, workers=8)
Actor weights initialized the same between local and target
Critic weights initialized the same between local and target

Training agent iteration 1 action std 0.990000 training loss actor 9.044483 and critic 84.344374
Training agent iteration 2 action std 0.980100 training loss actor 9.024422 and critic 76.770253
Training agent iteration 3 action std 0.970299 training loss actor 8.944698 and critic 59.041210
Training agent iteration 4 action std 0.960596 training loss actor 8.830077 and critic 45.656571
Training agent iteration 5 action std 0.950990 training loss actor 8.756071 and critic 37.319130
Training agent iteration 6 action std 0.941480 training loss actor 8.574824 and critic 21.279516
Training agent iteration 7 action std 0.932065 training loss actor 8.407418 and critic 8.328429
Training agent iteration 8 action std 0.922745 training loss actor 8.226251 and critic 4.450083
Training agent iteration 9 action std 0.913517 training loss actor 8.042618 and critic 4.025860
Training agent iteration 10 action std 0.904382 training loss actor 7.859958 and critic 3.920757
Training agent iteration 11 action std 0.895338 training loss actor 7.709072 and critic 3.772775
Training agent iteration 12 action std 0.886385 training loss actor 7.542667 and critic 3.545061
Training agent iteration 13 action std 0.877521 training loss actor 7.377706 and critic 3.310079
Training agent iteration 14 action std 0.868746 training loss actor 7.228774 and critic 3.196983
Training agent iteration 15 action std 0.860058 training loss actor 7.054730 and critic 3.114242
Training agent iteration 16 action std 0.851458 training loss actor 6.854509 and critic 3.016677
Training agent iteration 17 action std 0.842943 training loss actor 6.667233 and critic 2.888358
Training agent iteration 18 action std 0.834514 training loss actor 6.506879 and critic 2.733035
Training agent iteration 19 action std 0.826169 training loss actor 6.334184 and critic 2.640802
Training agent iteration 20 action std 0.817907 training loss actor 6.171668 and critic 2.495020
Training agent iteration 21 action std 0.809728 training loss actor 6.012084 and critic 2.358001
Training agent iteration 22 action std 0.801631 training loss actor 5.856321 and critic 2.305660
Training agent iteration 23 action std 0.793614 training loss actor 5.710386 and critic 2.253524
Training agent iteration 24 action std 0.785678 training loss actor 5.553827 and critic 2.163921
Training agent iteration 25 action std 0.777821 training loss actor 5.410910 and critic 2.066758
Training agent iteration 26 action std 0.770043 training loss actor 5.294514 and critic 2.005000
Training agent iteration 27 action std 0.762343 training loss actor 5.136726 and critic 1.866967
Training agent iteration 28 action std 0.754719 training loss actor 4.971675 and critic 1.818822
Training agent iteration 29 action std 0.747172 training loss actor 4.839141 and critic 1.773676
Training agent iteration 30 action std 0.739700 training loss actor 4.688489 and critic 1.729909
Training agent iteration 31 action std 0.732303 training loss actor 4.543104 and critic 1.625643
Training agent iteration 32 action std 0.724980 training loss actor 4.393867 and critic 1.579739
Training agent iteration 33 action std 0.717731 training loss actor 4.259092 and critic 1.484833
Training agent iteration 34 action std 0.710553 training loss actor 4.113039 and critic 1.412577
Training agent iteration 35 action std 0.703448 training loss actor 3.975992 and critic 1.335316
Training agent iteration 36 action std 0.696413 training loss actor 3.857262 and critic 1.287994
Training agent iteration 37 action std 0.689449 training loss actor 3.733943 and critic 1.213955
Training agent iteration 38 action std 0.682555 training loss actor 3.607378 and critic 1.196542
Training agent iteration 39 action std 0.675729 training loss actor 3.519959 and critic 1.141820
Training agent iteration 40 action std 0.668972 training loss actor 3.396802 and critic 1.110153
Training agent iteration 41 action std 0.662282 training loss actor 3.261140 and critic 1.067006
Training agent iteration 42 action std 0.655659 training loss actor 3.151168 and critic 1.015648
Training agent iteration 43 action std 0.649103 training loss actor 3.026166 and critic 0.961525
Training agent iteration 44 action std 0.642612 training loss actor 2.891623 and critic 0.926867
Training agent iteration 45 action std 0.636185 training loss actor 2.793288 and critic 0.894008
Training agent iteration 46 action std 0.629824 training loss actor 2.686535 and critic 0.854482
Training agent iteration 47 action std 0.623525 training loss actor 2.572778 and critic 0.824566
Training agent iteration 48 action std 0.617290 training loss actor 2.470931 and critic 0.790742
Training agent iteration 49 action std 0.611117 training loss actor 2.360041 and critic 0.753563
Training agent iteration 50 action std 0.605006 training loss actor 2.244612 and critic 0.708756
Evaluation: Average score is -0.293 and average game_len is 998 training loss actor 2.244612 and critic 0.708756

Training agent iteration 51 action std 0.598956 training loss actor 2.142388 and critic 0.684900
Training agent iteration 52 action std 0.592966 training loss actor 2.037870 and critic 0.668050
Training agent iteration 53 action std 0.587037 training loss actor 1.937690 and critic 0.631976
Training agent iteration 54 action std 0.581166 training loss actor 1.851903 and critic 0.621357
Training agent iteration 55 action std 0.575355 training loss actor 1.752097 and critic 0.595857
Training agent iteration 56 action std 0.569601 training loss actor 1.669428 and critic 0.582050
Training agent iteration 57 action std 0.563905 training loss actor 1.597596 and critic 0.556448
Training agent iteration 58 action std 0.558266 training loss actor 1.515681 and critic 0.550007
Training agent iteration 59 action std 0.552683 training loss actor 1.436878 and critic 0.528993
Training agent iteration 60 action std 0.547157 training loss actor 1.359704 and critic 0.513444
Training agent iteration 61 action std 0.541685 training loss actor 1.280118 and critic 0.484975
Training agent iteration 62 action std 0.536268 training loss actor 1.192570 and critic 0.478008
Training agent iteration 63 action std 0.530906 training loss actor 1.112168 and critic 0.454198
Training agent iteration 64 action std 0.525596 training loss actor 1.030926 and critic 0.424857
Training agent iteration 65 action std 0.520341 training loss actor 0.979533 and critic 0.408603
Training agent iteration 66 action std 0.515137 training loss actor 0.898075 and critic 0.387718
Training agent iteration 67 action std 0.509986 training loss actor 0.835161 and critic 0.369865
Training agent iteration 68 action std 0.504886 training loss actor 0.763314 and critic 0.355433
Training agent iteration 69 action std 0.499837 training loss actor 0.702771 and critic 0.341974
Training agent iteration 70 action std 0.494839 training loss actor 0.638172 and critic 0.327554
Training agent iteration 71 action std 0.489890 training loss actor 0.595448 and critic 0.325380
Training agent iteration 72 action std 0.484991 training loss actor 0.541682 and critic 0.311333
Training agent iteration 73 action std 0.480141 training loss actor 0.493456 and critic 0.299719
Training agent iteration 74 action std 0.475340 training loss actor 0.444369 and critic 0.288779
Training agent iteration 75 action std 0.470587 training loss actor 0.391645 and critic 0.279496
Training agent iteration 76 action std 0.465881 training loss actor 0.337695 and critic 0.266268
Training agent iteration 77 action std 0.461222 training loss actor 0.287878 and critic 0.251944
Training agent iteration 78 action std 0.456610 training loss actor 0.247229 and critic 0.238787
Training agent iteration 79 action std 0.452044 training loss actor 0.201736 and critic 0.225527
Training agent iteration 80 action std 0.447523 training loss actor 0.156343 and critic 0.214453
Training agent iteration 81 action std 0.443048 training loss actor 0.108678 and critic 0.206141
Training agent iteration 82 action std 0.438618 training loss actor 0.069800 and critic 0.201172
Training agent iteration 83 action std 0.434231 training loss actor 0.028527 and critic 0.194447
Training agent iteration 84 action std 0.429889 training loss actor -0.004789 and critic 0.188035
Training agent iteration 85 action std 0.425590 training loss actor -0.035960 and critic 0.180744
Training agent iteration 86 action std 0.421334 training loss actor -0.065881 and critic 0.172312
Training agent iteration 87 action std 0.417121 training loss actor -0.094957 and critic 0.161469
Training agent iteration 88 action std 0.412950 training loss actor -0.117193 and critic 0.155526
Training agent iteration 89 action std 0.408820 training loss actor -0.152697 and critic 0.148784
Training agent iteration 90 action std 0.404732 training loss actor -0.189288 and critic 0.140331
Training agent iteration 91 action std 0.400685 training loss actor -0.215499 and critic 0.135683
Training agent iteration 92 action std 0.396678 training loss actor -0.250236 and critic 0.131487
Training agent iteration 93 action std 0.392711 training loss actor -0.280955 and critic 0.126601
Training agent iteration 94 action std 0.388784 training loss actor -0.300794 and critic 0.124415
Training agent iteration 95 action std 0.384896 training loss actor -0.314223 and critic 0.119662
Training agent iteration 96 action std 0.381047 training loss actor -0.341588 and critic 0.113971
Training agent iteration 97 action std 0.377237 training loss actor -0.354381 and critic 0.110076
Training agent iteration 98 action std 0.373464 training loss actor -0.372269 and critic 0.103269
Training agent iteration 99 action std 0.369730 training loss actor -0.387614 and critic 0.099144
Training agent iteration 100 action std 0.366032 training loss actor -0.408334 and critic 0.097128
Evaluation: Average score is -0.012 and average game_len is 998 training loss actor -0.408334 and critic 0.097128

Training agent iteration 101 action std 0.362372 training loss actor -0.414040 and critic 0.093596
Training agent iteration 102 action std 0.358748 training loss actor -0.428443 and critic 0.090091
Training agent iteration 103 action std 0.355161 training loss actor -0.439975 and critic 0.088430
Training agent iteration 104 action std 0.351609 training loss actor -0.456816 and critic 0.085429
Training agent iteration 105 action std 0.348093 training loss actor -0.466561 and critic 0.083839
Training agent iteration 106 action std 0.344612 training loss actor -0.484520 and critic 0.080234
Training agent iteration 107 action std 0.341166 training loss actor -0.496967 and critic 0.075558
Training agent iteration 108 action std 0.337754 training loss actor -0.508449 and critic 0.072461
Training agent iteration 109 action std 0.334377 training loss actor -0.517913 and critic 0.068383
Training agent iteration 110 action std 0.331033 training loss actor -0.529669 and critic 0.063513
Training agent iteration 111 action std 0.327723 training loss actor -0.536237 and critic 0.061232
Training agent iteration 112 action std 0.324446 training loss actor -0.545746 and critic 0.059838
Training agent iteration 113 action std 0.321201 training loss actor -0.551766 and critic 0.057501
Training agent iteration 114 action std 0.317989 training loss actor -0.556669 and critic 0.055160
Training agent iteration 115 action std 0.314809 training loss actor -0.561061 and critic 0.054503
Training agent iteration 116 action std 0.311661 training loss actor -0.570289 and critic 0.051701
Training agent iteration 117 action std 0.308544 training loss actor -0.574346 and critic 0.048013
Training agent iteration 118 action std 0.305459 training loss actor -0.576101 and critic 0.046355
Training agent iteration 119 action std 0.302404 training loss actor -0.578187 and critic 0.044973
Training agent iteration 120 action std 0.299380 training loss actor -0.584617 and critic 0.042799
Training agent iteration 121 action std 0.296387 training loss actor -0.585903 and critic 0.040797
Training agent iteration 122 action std 0.293423 training loss actor -0.590516 and critic 0.040197
Training agent iteration 123 action std 0.290488 training loss actor -0.595514 and critic 0.038895
Training agent iteration 124 action std 0.287584 training loss actor -0.602771 and critic 0.037667
Training agent iteration 125 action std 0.284708 training loss actor -0.604856 and critic 0.035339
Training agent iteration 126 action std 0.281861 training loss actor -0.603140 and critic 0.035386
Training agent iteration 127 action std 0.279042 training loss actor -0.603643 and critic 0.034368
Training agent iteration 128 action std 0.276252 training loss actor -0.604608 and critic 0.033048
Training agent iteration 129 action std 0.273489 training loss actor -0.604346 and critic 0.031184
Training agent iteration 130 action std 0.270754 training loss actor -0.603978 and critic 0.029895
Training agent iteration 131 action std 0.268047 training loss actor -0.604839 and critic 0.028075
Training agent iteration 132 action std 0.265366 training loss actor -0.605530 and critic 0.027359
Training agent iteration 133 action std 0.262713 training loss actor -0.602967 and critic 0.025800
Training agent iteration 134 action std 0.260085 training loss actor -0.601334 and critic 0.024850
Training agent iteration 135 action std 0.257485 training loss actor -0.598023 and critic 0.024064
Training agent iteration 136 action std 0.254910 training loss actor -0.595917 and critic 0.023208
Training agent iteration 137 action std 0.252361 training loss actor -0.591642 and critic 0.021716
Training agent iteration 138 action std 0.249837 training loss actor -0.590976 and critic 0.021233
Training agent iteration 139 action std 0.247339 training loss actor -0.587740 and critic 0.019937
Training agent iteration 140 action std 0.244865 training loss actor -0.585701 and critic 0.019075
Training agent iteration 141 action std 0.242417 training loss actor -0.582692 and critic 0.018306
Training agent iteration 142 action std 0.239992 training loss actor -0.578135 and critic 0.017544
Training agent iteration 143 action std 0.237593 training loss actor -0.572941 and critic 0.016721
Training agent iteration 144 action std 0.235217 training loss actor -0.568899 and critic 0.016520
Training agent iteration 145 action std 0.232864 training loss actor -0.565150 and critic 0.015967
Training agent iteration 146 action std 0.230536 training loss actor -0.561821 and critic 0.015345
Training agent iteration 147 action std 0.228230 training loss actor -0.559965 and critic 0.014819
Training agent iteration 148 action std 0.225948 training loss actor -0.557269 and critic 0.013960
Training agent iteration 149 action std 0.223689 training loss actor -0.554356 and critic 0.013549
Training agent iteration 150 action std 0.221452 training loss actor -0.550530 and critic 0.012936
Evaluation: Average score is -0.049 and average game_len is 998 training loss actor -0.550530 and critic 0.012936

Training agent iteration 151 action std 0.219237 training loss actor -0.547408 and critic 0.012396
Training agent iteration 152 action std 0.217045 training loss actor -0.543445 and critic 0.012030
Training agent iteration 153 action std 0.214874 training loss actor -0.539967 and critic 0.011765
Training agent iteration 154 action std 0.212726 training loss actor -0.535516 and critic 0.011273
Training agent iteration 155 action std 0.210598 training loss actor -0.532220 and critic 0.010867
Training agent iteration 156 action std 0.208492 training loss actor -0.527876 and critic 0.010322
Training agent iteration 157 action std 0.206408 training loss actor -0.521564 and critic 0.009902
Training agent iteration 158 action std 0.204343 training loss actor -0.516727 and critic 0.009531
Training agent iteration 159 action std 0.202300 training loss actor -0.511924 and critic 0.009252
Training agent iteration 160 action std 0.200277 training loss actor -0.506020 and critic 0.008819
Training agent iteration 161 action std 0.198274 training loss actor -0.500693 and critic 0.008678
Training agent iteration 162 action std 0.196292 training loss actor -0.497643 and critic 0.008495
Training agent iteration 163 action std 0.194329 training loss actor -0.493523 and critic 0.008025
Training agent iteration 164 action std 0.192385 training loss actor -0.487368 and critic 0.007646
Training agent iteration 165 action std 0.190461 training loss actor -0.482113 and critic 0.007403
Training agent iteration 166 action std 0.188557 training loss actor -0.478233 and critic 0.007086
Training agent iteration 167 action std 0.186671 training loss actor -0.472845 and critic 0.006779
Training agent iteration 168 action std 0.184805 training loss actor -0.467946 and critic 0.006592
Training agent iteration 169 action std 0.182957 training loss actor -0.464195 and critic 0.006360
Training agent iteration 170 action std 0.181127 training loss actor -0.459857 and critic 0.006070
Training agent iteration 171 action std 0.179316 training loss actor -0.454213 and critic 0.005714
Training agent iteration 172 action std 0.177523 training loss actor -0.448787 and critic 0.005374
Training agent iteration 173 action std 0.175747 training loss actor -0.444008 and critic 0.005255
Training agent iteration 174 action std 0.173990 training loss actor -0.439759 and critic 0.005165
Training agent iteration 175 action std 0.172250 training loss actor -0.435260 and critic 0.005000
Training agent iteration 176 action std 0.170527 training loss actor -0.430966 and critic 0.004708
Training agent iteration 177 action std 0.168822 training loss actor -0.426215 and critic 0.004538
Training agent iteration 178 action std 0.167134 training loss actor -0.420110 and critic 0.004295
Training agent iteration 179 action std 0.165463 training loss actor -0.415063 and critic 0.003970
Training agent iteration 180 action std 0.163808 training loss actor -0.409400 and critic 0.003836
Training agent iteration 181 action std 0.162170 training loss actor -0.403243 and critic 0.003879
Training agent iteration 182 action std 0.160548 training loss actor -0.398931 and critic 0.003858
Training agent iteration 183 action std 0.158943 training loss actor -0.394628 and critic 0.003717
Training agent iteration 184 action std 0.157353 training loss actor -0.391243 and critic 0.003549
Training agent iteration 185 action std 0.155780 training loss actor -0.387480 and critic 0.003457
Training agent iteration 186 action std 0.154222 training loss actor -0.383860 and critic 0.003213
Training agent iteration 187 action std 0.152680 training loss actor -0.379379 and critic 0.002980
Training agent iteration 188 action std 0.151153 training loss actor -0.375226 and critic 0.002903
Training agent iteration 189 action std 0.149641 training loss actor -0.370175 and critic 0.002874
Training agent iteration 190 action std 0.148145 training loss actor -0.365360 and critic 0.002761
Training agent iteration 191 action std 0.146664 training loss actor -0.360910 and critic 0.002681
Training agent iteration 192 action std 0.145197 training loss actor -0.356424 and critic 0.002599
Training agent iteration 193 action std 0.143745 training loss actor -0.351938 and critic 0.002469
Training agent iteration 194 action std 0.142307 training loss actor -0.346743 and critic 0.002323
Training agent iteration 195 action std 0.140884 training loss actor -0.342520 and critic 0.002180
Training agent iteration 196 action std 0.139476 training loss actor -0.338079 and critic 0.002125
Training agent iteration 197 action std 0.138081 training loss actor -0.333805 and critic 0.002059
Training agent iteration 198 action std 0.136700 training loss actor -0.329071 and critic 0.001964
Training agent iteration 199 action std 0.135333 training loss actor -0.324624 and critic 0.001915
Training agent iteration 200 action std 0.133980 training loss actor -0.319867 and critic 0.001871
Evaluation: Average score is -0.078 and average game_len is 998 training loss actor -0.319867 and critic 0.001871
Environment solved in 200 iterations!	Average Score: -0.08
saving models ...
