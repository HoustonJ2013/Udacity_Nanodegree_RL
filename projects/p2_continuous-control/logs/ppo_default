Namespace(actor_fc_units=5, batch_size=128, buffer_size=10000, critic_fc_units1=2, critic_fc_units2=5, critic_fc_units3=5, device='cpu', env='MountainCarContinuous-v0', eps_decay=0.999, eps_end=0.01, eps_start=1.0, evaluate_n_iter=50, gamma=0.99, loss='mse', lr=0.0005, lr_actor=0.001, lr_critic=0.005, max_t=2000, n_iterations=200, per=False, save_replay=False, score_threshold=200, score_window_size=100, tau=0.001, testname='ppo_default', update_every=1, weight_decay=0, workers=8)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
Current environment is  MountainCarContinuous-v0
State size is 2
action size is 1
A typical state looks like [[0.43173053 0.5       ]]
Test parameters Namespace(actor_fc_units=5, batch_size=128, buffer_size=10000, critic_fc_units1=2, critic_fc_units2=5, critic_fc_units3=5, device='cpu', env='MountainCarContinuous-v0', eps_decay=0.999, eps_end=0.01, eps_start=1.0, evaluate_n_iter=50, gamma=0.99, loss='mse', lr=0.0005, lr_actor=0.001, lr_critic=0.005, max_t=2000, n_iterations=200, per=False, save_replay=False, score_threshold=200, score_window_size=100, tau=0.001, testname='ppo_default', update_every=1, weight_decay=0, workers=8)
Actor weights initialized the same between local and target
Critic weights initialized the same between local and target

Training agent iteration 1 action std 0.990000 training loss actor 8.831695 and critic 82.054766
Training agent iteration 2 action std 0.980100 training loss actor 8.712715 and critic 76.728296
Training agent iteration 3 action std 0.970299 training loss actor 8.690320 and critic 71.430129
Training agent iteration 4 action std 0.960596 training loss actor 8.621680 and critic 62.295565
Training agent iteration 5 action std 0.950990 training loss actor 8.573427 and critic 52.004760
Training agent iteration 6 action std 0.941480 training loss actor 8.378349 and critic 36.695113
Training agent iteration 7 action std 0.932065 training loss actor 8.216603 and critic 23.221374
Training agent iteration 8 action std 0.922745 training loss actor 8.011566 and critic 11.931993
Training agent iteration 9 action std 0.913517 training loss actor 7.819316 and critic 5.701104
Training agent iteration 10 action std 0.904382 training loss actor 7.572875 and critic 4.254826
Training agent iteration 11 action std 0.895338 training loss actor 7.392123 and critic 3.807080
Training agent iteration 12 action std 0.886385 training loss actor 7.222550 and critic 3.668888
Training agent iteration 13 action std 0.877521 training loss actor 7.079695 and critic 3.505914
Training agent iteration 14 action std 0.868746 training loss actor 6.887328 and critic 3.364602
Training agent iteration 15 action std 0.860058 training loss actor 6.778425 and critic 3.249816
Training agent iteration 16 action std 0.851458 training loss actor 6.646755 and critic 3.273467
Training agent iteration 17 action std 0.842943 training loss actor 6.488711 and critic 3.194295
Training agent iteration 18 action std 0.834514 training loss actor 6.309312 and critic 3.041202
Training agent iteration 19 action std 0.826169 training loss actor 6.177249 and critic 2.924806
Training agent iteration 20 action std 0.817907 training loss actor 5.997246 and critic 2.859365
Training agent iteration 21 action std 0.809728 training loss actor 5.822789 and critic 2.678894
Training agent iteration 22 action std 0.801631 training loss actor 5.658338 and critic 2.559591
Training agent iteration 23 action std 0.793614 training loss actor 5.503102 and critic 2.427109
Training agent iteration 24 action std 0.785678 training loss actor 5.338510 and critic 2.361353
Training agent iteration 25 action std 0.777821 training loss actor 5.188548 and critic 2.231553
Training agent iteration 26 action std 0.770043 training loss actor 5.062163 and critic 2.150900
Training agent iteration 27 action std 0.762343 training loss actor 4.933579 and critic 2.085839
Training agent iteration 28 action std 0.754719 training loss actor 4.773576 and critic 2.039244
Training agent iteration 29 action std 0.747172 training loss actor 4.636689 and critic 1.981894
Training agent iteration 30 action std 0.739700 training loss actor 4.507801 and critic 1.927230
Training agent iteration 31 action std 0.732303 training loss actor 4.359510 and critic 1.824679
Training agent iteration 32 action std 0.724980 training loss actor 4.219394 and critic 1.746971
Training agent iteration 33 action std 0.717731 training loss actor 4.099904 and critic 1.674671
Training agent iteration 34 action std 0.710553 training loss actor 3.972577 and critic 1.634980
Training agent iteration 35 action std 0.703448 training loss actor 3.839973 and critic 1.559133
Training agent iteration 36 action std 0.696413 training loss actor 3.720167 and critic 1.536582
Training agent iteration 37 action std 0.689449 training loss actor 3.596461 and critic 1.464192
Training agent iteration 38 action std 0.682555 training loss actor 3.494717 and critic 1.414198
Training agent iteration 39 action std 0.675729 training loss actor 3.386405 and critic 1.312161
Training agent iteration 40 action std 0.668972 training loss actor 3.245754 and critic 1.261781
Training agent iteration 41 action std 0.662282 training loss actor 3.125201 and critic 1.197718
Training agent iteration 42 action std 0.655659 training loss actor 2.988446 and critic 1.157620
Training agent iteration 43 action std 0.649103 training loss actor 2.846402 and critic 1.090898
Training agent iteration 44 action std 0.642612 training loss actor 2.733073 and critic 1.078583
Training agent iteration 45 action std 0.636185 training loss actor 2.644670 and critic 1.036444
Training agent iteration 46 action std 0.629824 training loss actor 2.556027 and critic 1.003237
Training agent iteration 47 action std 0.623525 training loss actor 2.472944 and critic 0.960446
Training agent iteration 48 action std 0.617290 training loss actor 2.377514 and critic 0.948015
Training agent iteration 49 action std 0.611117 training loss actor 2.275968 and critic 0.913058
Training agent iteration 50 action std 0.605006 training loss actor 2.168126 and critic 0.906146
Evaluation: Average score is -4.937 and average game_len is 998 training loss actor 2.168126 and critic 0.906146

Training agent iteration 51 action std 0.598956 training loss actor 2.063156 and critic 0.889696
Training agent iteration 52 action std 0.592966 training loss actor 1.957922 and critic 0.879979
Training agent iteration 53 action std 0.587037 training loss actor 1.894404 and critic 0.858022
Training agent iteration 54 action std 0.581166 training loss actor 1.811875 and critic 0.837271
Training agent iteration 55 action std 0.575355 training loss actor 1.732815 and critic 0.808218
Training agent iteration 56 action std 0.569601 training loss actor 1.632170 and critic 0.765416
Training agent iteration 57 action std 0.563905 training loss actor 1.559930 and critic 0.729099
Training agent iteration 58 action std 0.558266 training loss actor 1.462540 and critic 0.698011
Training agent iteration 59 action std 0.552683 training loss actor 1.368675 and critic 0.661353
Training agent iteration 60 action std 0.547157 training loss actor 1.283362 and critic 0.631837
Training agent iteration 61 action std 0.541685 training loss actor 1.231033 and critic 0.621185
Training agent iteration 62 action std 0.536268 training loss actor 1.167826 and critic 0.623635
Training agent iteration 63 action std 0.530906 training loss actor 1.087091 and critic 0.609812
Training agent iteration 64 action std 0.525596 training loss actor 1.028252 and critic 0.600662
Training agent iteration 65 action std 0.520341 training loss actor 0.962961 and critic 0.577441
Training agent iteration 66 action std 0.515137 training loss actor 0.898739 and critic 0.559944
Training agent iteration 67 action std 0.509986 training loss actor 0.826143 and critic 0.529759
Training agent iteration 68 action std 0.504886 training loss actor 0.774879 and critic 0.518797
Training agent iteration 69 action std 0.499837 training loss actor 0.713170 and critic 0.494630
Training agent iteration 70 action std 0.494839 training loss actor 0.669111 and critic 0.486314
Training agent iteration 71 action std 0.489890 training loss actor 0.613284 and critic 0.468793
Training agent iteration 72 action std 0.484991 training loss actor 0.569038 and critic 0.449466
Training agent iteration 73 action std 0.480141 training loss actor 0.516565 and critic 0.435477
Training agent iteration 74 action std 0.475340 training loss actor 0.476839 and critic 0.440439
Training agent iteration 75 action std 0.470587 training loss actor 0.416551 and critic 0.425565
Training agent iteration 76 action std 0.465881 training loss actor 0.360803 and critic 0.414878
Training agent iteration 77 action std 0.461222 training loss actor 0.321528 and critic 0.420191
Training agent iteration 78 action std 0.456610 training loss actor 0.280920 and critic 0.405335
Training agent iteration 79 action std 0.452044 training loss actor 0.235610 and critic 0.387098
Training agent iteration 80 action std 0.447523 training loss actor 0.200236 and critic 0.379753
Training agent iteration 81 action std 0.443048 training loss actor 0.176412 and critic 0.377356
Training agent iteration 82 action std 0.438618 training loss actor 0.128232 and critic 0.363870
Training agent iteration 83 action std 0.434231 training loss actor 0.077253 and critic 0.353805
Training agent iteration 84 action std 0.429889 training loss actor 0.050314 and critic 0.349775
Training agent iteration 85 action std 0.425590 training loss actor 0.017514 and critic 0.344922
Training agent iteration 86 action std 0.421334 training loss actor -0.023583 and critic 0.327581
Training agent iteration 87 action std 0.417121 training loss actor -0.061692 and critic 0.316446
Training agent iteration 88 action std 0.412950 training loss actor -0.077848 and critic 0.310356
Training agent iteration 89 action std 0.408820 training loss actor -0.125453 and critic 0.295395
Training agent iteration 90 action std 0.404732 training loss actor -0.151126 and critic 0.287723
Training agent iteration 91 action std 0.400685 training loss actor -0.180491 and critic 0.286348
Training agent iteration 92 action std 0.396678 training loss actor -0.205982 and critic 0.278321
Training agent iteration 93 action std 0.392711 training loss actor -0.237596 and critic 0.275658
Training agent iteration 94 action std 0.388784 training loss actor -0.252782 and critic 0.273495
Training agent iteration 95 action std 0.384896 training loss actor -0.276657 and critic 0.263137
Training agent iteration 96 action std 0.381047 training loss actor -0.297059 and critic 0.252705
Training agent iteration 97 action std 0.377237 training loss actor -0.321809 and critic 0.248049
Training agent iteration 98 action std 0.373464 training loss actor -0.338391 and critic 0.237744
Training agent iteration 99 action std 0.369730 training loss actor -0.364987 and critic 0.231425
Training agent iteration 100 action std 0.366032 training loss actor -0.385061 and critic 0.225620
Evaluation: Average score is -7.719 and average game_len is 998 training loss actor -0.385061 and critic 0.225620

Training agent iteration 101 action std 0.362372 training loss actor -0.409587 and critic 0.217838
Training agent iteration 102 action std 0.358748 training loss actor -0.424649 and critic 0.212632
Training agent iteration 103 action std 0.355161 training loss actor -0.450453 and critic 0.210095
Training agent iteration 104 action std 0.351609 training loss actor -0.468818 and critic 0.205243
Training agent iteration 105 action std 0.348093 training loss actor -0.498083 and critic 0.203696
Training agent iteration 106 action std 0.344612 training loss actor -0.512202 and critic 0.201237
Training agent iteration 107 action std 0.341166 training loss actor -0.521273 and critic 0.196708
Training agent iteration 108 action std 0.337754 training loss actor -0.537566 and critic 0.189531
Training agent iteration 109 action std 0.334377 training loss actor -0.557078 and critic 0.182125
Training agent iteration 110 action std 0.331033 training loss actor -0.567527 and critic 0.176252
Training agent iteration 111 action std 0.327723 training loss actor -0.587676 and critic 0.172986
Training agent iteration 112 action std 0.324446 training loss actor -0.607707 and critic 0.169925
Training agent iteration 113 action std 0.321201 training loss actor -0.612532 and critic 0.164900
Training agent iteration 114 action std 0.317989 training loss actor -0.615984 and critic 0.164977
Training agent iteration 115 action std 0.314809 training loss actor -0.622655 and critic 0.162909
Training agent iteration 116 action std 0.311661 training loss actor -0.626968 and critic 0.159586
Training agent iteration 117 action std 0.308544 training loss actor -0.626805 and critic 0.153531
Training agent iteration 118 action std 0.305459 training loss actor -0.633917 and critic 0.151743
Training agent iteration 119 action std 0.302404 training loss actor -0.639466 and critic 0.141878
Training agent iteration 120 action std 0.300000 training loss actor -0.645174 and critic 0.139691
Training agent iteration 121 action std 0.300000 training loss actor -0.650170 and critic 0.135531
Training agent iteration 122 action std 0.300000 training loss actor -0.656996 and critic 0.134954
Training agent iteration 123 action std 0.300000 training loss actor -0.656779 and critic 0.134604
Training agent iteration 124 action std 0.300000 training loss actor -0.655214 and critic 0.138732
Training agent iteration 125 action std 0.300000 training loss actor -0.644975 and critic 0.136761
Training agent iteration 126 action std 0.300000 training loss actor -0.624928 and critic 0.141709
Training agent iteration 127 action std 0.300000 training loss actor -0.615615 and critic 0.142620
Training agent iteration 128 action std 0.300000 training loss actor -0.602580 and critic 0.140834
Training agent iteration 129 action std 0.300000 training loss actor -0.588555 and critic 0.142935
Training agent iteration 130 action std 0.300000 training loss actor -0.574825 and critic 0.145295
Training agent iteration 131 action std 0.300000 training loss actor -0.569999 and critic 0.142082
Training agent iteration 132 action std 0.300000 training loss actor -0.552247 and critic 0.144248
Training agent iteration 133 action std 0.300000 training loss actor -0.538687 and critic 0.145700
Training agent iteration 134 action std 0.300000 training loss actor -0.528031 and critic 0.143212
Training agent iteration 135 action std 0.300000 training loss actor -0.523434 and critic 0.139833
Training agent iteration 136 action std 0.300000 training loss actor -0.513005 and critic 0.141989
Training agent iteration 137 action std 0.300000 training loss actor -0.503813 and critic 0.139225
Training agent iteration 138 action std 0.300000 training loss actor -0.493767 and critic 0.141163
Training agent iteration 139 action std 0.300000 training loss actor -0.476064 and critic 0.140481
Training agent iteration 140 action std 0.300000 training loss actor -0.453178 and critic 0.145084
Training agent iteration 141 action std 0.300000 training loss actor -0.433292 and critic 0.148845
Training agent iteration 142 action std 0.300000 training loss actor -0.423193 and critic 0.148397
Training agent iteration 143 action std 0.300000 training loss actor -0.410954 and critic 0.145296
Training agent iteration 144 action std 0.300000 training loss actor -0.396325 and critic 0.147829
Training agent iteration 145 action std 0.300000 training loss actor -0.387380 and critic 0.145410
Training agent iteration 146 action std 0.300000 training loss actor -0.379882 and critic 0.143403
Training agent iteration 147 action std 0.300000 training loss actor -0.361131 and critic 0.146885
Training agent iteration 148 action std 0.300000 training loss actor -0.349564 and critic 0.151041
Training agent iteration 149 action std 0.300000 training loss actor -0.349906 and critic 0.149918
Training agent iteration 150 action std 0.300000 training loss actor -0.342309 and critic 0.152805
Evaluation: Average score is -9.032 and average game_len is 998 training loss actor -0.342309 and critic 0.152805

Training agent iteration 151 action std 0.300000 training loss actor -0.331089 and critic 0.153555
Training agent iteration 152 action std 0.300000 training loss actor -0.329687 and critic 0.153970
Training agent iteration 153 action std 0.300000 training loss actor -0.322630 and critic 0.154261
Training agent iteration 154 action std 0.300000 training loss actor -0.303036 and critic 0.157197
Training agent iteration 155 action std 0.300000 training loss actor -0.291837 and critic 0.156635
Training agent iteration 156 action std 0.300000 training loss actor -0.284609 and critic 0.158018
Training agent iteration 157 action std 0.300000 training loss actor -0.274397 and critic 0.158621
Training agent iteration 158 action std 0.300000 training loss actor -0.264001 and critic 0.160774
Training agent iteration 159 action std 0.300000 training loss actor -0.260729 and critic 0.161791
Training agent iteration 160 action std 0.300000 training loss actor -0.258045 and critic 0.162701
Training agent iteration 161 action std 0.300000 training loss actor -0.247872 and critic 0.164508
Training agent iteration 162 action std 0.300000 training loss actor -0.241595 and critic 0.165468
Training agent iteration 163 action std 0.300000 training loss actor -0.228196 and critic 0.164613
Training agent iteration 164 action std 0.300000 training loss actor -0.226079 and critic 0.162169
Training agent iteration 165 action std 0.300000 training loss actor -0.210826 and critic 0.161662
Training agent iteration 166 action std 0.300000 training loss actor -0.197870 and critic 0.160835
Training agent iteration 167 action std 0.300000 training loss actor -0.194531 and critic 0.162870
Training agent iteration 168 action std 0.300000 training loss actor -0.198038 and critic 0.161677
Training agent iteration 169 action std 0.300000 training loss actor -0.182686 and critic 0.163777
Training agent iteration 170 action std 0.300000 training loss actor -0.182216 and critic 0.167426
Training agent iteration 171 action std 0.300000 training loss actor -0.189329 and critic 0.165196
Training agent iteration 172 action std 0.300000 training loss actor -0.174639 and critic 0.163556
Training agent iteration 173 action std 0.300000 training loss actor -0.163281 and critic 0.166841
Training agent iteration 174 action std 0.300000 training loss actor -0.160853 and critic 0.168682
Training agent iteration 175 action std 0.300000 training loss actor -0.149061 and critic 0.166436
Training agent iteration 176 action std 0.300000 training loss actor -0.138670 and critic 0.166848
Training agent iteration 177 action std 0.300000 training loss actor -0.134460 and critic 0.165570
Training agent iteration 178 action std 0.300000 training loss actor -0.128075 and critic 0.165782
Training agent iteration 179 action std 0.300000 training loss actor -0.114862 and critic 0.166664
Training agent iteration 180 action std 0.300000 training loss actor -0.125488 and critic 0.163980
Training agent iteration 181 action std 0.300000 training loss actor -0.128304 and critic 0.165003
Training agent iteration 182 action std 0.300000 training loss actor -0.117641 and critic 0.168294
Training agent iteration 183 action std 0.300000 training loss actor -0.109509 and critic 0.169772
Training agent iteration 184 action std 0.300000 training loss actor -0.111627 and critic 0.169978
Training agent iteration 185 action std 0.300000 training loss actor -0.101885 and critic 0.170656
Training agent iteration 186 action std 0.300000 training loss actor -0.088171 and critic 0.168981
Training agent iteration 187 action std 0.300000 training loss actor -0.084104 and critic 0.168654
Training agent iteration 188 action std 0.300000 training loss actor -0.088388 and critic 0.168875
Training agent iteration 189 action std 0.300000 training loss actor -0.092316 and critic 0.165656
Training agent iteration 190 action std 0.300000 training loss actor -0.082009 and critic 0.170169
Training agent iteration 191 action std 0.300000 training loss actor -0.074040 and critic 0.171508
Training agent iteration 192 action std 0.300000 training loss actor -0.082270 and critic 0.171160
Training agent iteration 193 action std 0.300000 training loss actor -0.073179 and critic 0.168332
Training agent iteration 194 action std 0.300000 training loss actor -0.065968 and critic 0.170011
Training agent iteration 195 action std 0.300000 training loss actor -0.069654 and critic 0.167054
Training agent iteration 196 action std 0.300000 training loss actor -0.074365 and critic 0.165774
Training agent iteration 197 action std 0.300000 training loss actor -0.067030 and critic 0.164654
Training agent iteration 198 action std 0.300000 training loss actor -0.057550 and critic 0.164821
Training agent iteration 199 action std 0.300000 training loss actor -0.049661 and critic 0.166666
Training agent iteration 200 action std 0.300000 training loss actor -0.034531 and critic 0.170921
Evaluation: Average score is -10.242 and average game_len is 998 training loss actor -0.034531 and critic 0.170921
Environment solved in 200 iterations!	Average Score: -10.24
saving models ...
